{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIzFpte8OeEALgrGfrWygF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalikumaribihiya1-byte/Object-detection-with-ai-/blob/main/Object_detection_with_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WITcfhFoxNJG"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics opencv-python-headless matplotlib pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "eJnZyc9Vz614"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "print(\"Uploaded:\", file_name)"
      ],
      "metadata": {
        "id": "Ls66KaLfz7PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "id": "jWDcRVCAz7Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model(file_name)\n",
        "annotated = results[0].plot()"
      ],
      "metadata": {
        "id": "SMpA0gRdz7gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(cv2.cvtColor(annotated,cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "vmskcRV8z7mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "video_path=list(uploaded.keys())[0]\n",
        "print(\"Uploaded:\",video_path)"
      ],
      "metadata": {
        "id": "D9TtH3X4z7rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path =\"output_detected.mp4\"\n",
        "cap=cv2.VideoCapture(video_path)\n",
        "width=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps=cap.get(cv2.CAP_PROP_FPS)or 25.0\n",
        "fourcc=cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out=cv2.VideoWriter(output_path,fourcc,fps,(width,height))\n",
        "\n",
        "frame_count=0\n",
        "while True:\n",
        "  ret,frame= cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "  results=model(frame)\n",
        "  annotated=results[0].plot()\n",
        "  out.write(annotated)\n",
        "  frame_count+=1\n",
        "  if frame_count%50==0:\n",
        "      print(f\"Processed {frame_count} frames\")\n",
        "  cap.release()\n",
        "  out.release()\n",
        "\n",
        "  print(\"Video Saved\", output_path)\n",
        "  files.download(output_path)"
      ],
      "metadata": {
        "id": "oAkI_FsG3Cy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics opencv-python-headless matplotlib pillow\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "model=YOLO('yolov8n.pt')\n",
        "\n",
        "def take_photo(filename='snapshot.jpg'):\n",
        "  js=\"\"\"\n",
        "  async function takePhoto() {\n",
        "    const div = document.createElement('div');\n",
        "    const capture = document.createElement('button');\n",
        "    capture.textContent = 'Capture';\n",
        "    div.appendChild(capture);\n",
        "    document.body.appeendChild(div);\n",
        "\n",
        "    const video = document.createElement('video');\n",
        "    video.style.display='block';\n",
        "    const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "    document.body.appendChild(video);\n",
        "    video.srcObject = stream;\n",
        "    await video.play();\n",
        "\n",
        "    // Resize window\n",
        "    google.colab.output.selfIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "    // Wait for capture button\n",
        "    await new Promise((resolve)=> capture.onclick= resolve);\n",
        "\n",
        "    const canvas = document.createElement('canvas');\n",
        "    canvas.width = video.videoWidth;\n",
        "    canvas.height = video.videoHeight;\n",
        "    canvas.getContext('2d').drawImage(video,0,0);\n",
        "    stream.getTracks().forEach(track => track.stop());\n",
        "    const imgData = canvas.toDataURL('image/jpeg').split(',')[1];\n",
        "    div.remove();\n",
        "    return imgData;\n",
        "  }\n",
        "  takePhoto();\n",
        "  \"\"\"\n",
        "\n",
        "  data=output.eval_js(js)\n",
        "  with open(filename, 'wb') as f:\n",
        "      f.write(b64decode(data))\n",
        "  return filename\n",
        "\n",
        "  filename = take_photo('snapshot.jpg')\n",
        "  print(\"Capture:\", filename)\n",
        "\n",
        "  results=model(filename)\n",
        "  annotated=results[0].plot()\n",
        "\n",
        "  plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "l6ArYVVh3C_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for img_name in uploaded.keys():\n",
        "    print(f\"Processing {img_name}...\")\n",
        "    results = model(img_name)\n",
        "    annotated = results[0].plot()\n",
        "    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8Xk79Cav3DO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics --quiet\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "X0jHTWR_4f_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "id": "NRLYl8G04gIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \"https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128.zip\" -o coco128.zip\n",
        "!unzip -q coco128.zip -d dataset\n",
        "!ls dataset/coco128"
      ],
      "metadata": {
        "id": "Bs1xPQUG4geO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset/coco128.yaml\n",
        "path: dataset/coco128\n",
        "train: images/train2017\n",
        "val: images/train2017\n",
        "\n",
        "nc:80\n",
        "names:\n",
        "0: person\n",
        "1: bicycle\n",
        "2: car\n",
        "3: motorcycle\n",
        "4: airplane\n",
        "5: bus\n",
        "6: train\n",
        "7: truck\n",
        "8: boat\n",
        "9: traffic light\n",
        "10: fire hydrant\n",
        "11: stop sign\n",
        "12: parking meter\n",
        "13: bench\n",
        "14: bird\n",
        "15: cat\n",
        "16: dog\n",
        "17: horse\n",
        "18: sheep\n",
        "19: cow\n",
        "20: elephant\n",
        "21: bear\n",
        "22: zebra\n",
        "23: giraffe\n",
        "24: backpack\n",
        "25: umbrella\n",
        "26: handbag\n",
        "27: tie\n",
        "28: suitcase\n",
        "29: frisbee\n",
        "30: skis\n",
        "31: snowboard\n",
        "32: sports ball\n",
        "33: kite\n",
        "34: baseball bat\n",
        "35: baseball glove\n",
        "36: skateboard\n",
        "37: surfboard\n",
        "38: tennis racket\n",
        "39: bottle\n",
        "40: wine glass\n",
        "41: cup\n",
        "42: fork\n",
        "43: knife\n",
        "44: spoon\n",
        "45: bowl\n",
        "46: banana\n",
        "47: apple\n",
        "48: sandwich\n",
        "49: orange\n",
        "50: broccoli\n",
        "51: carrot\n",
        "52: hot dog\n",
        "53: pizza\n",
        "54: donut\n",
        "55: cake\n",
        "56: chair\n",
        "57: couch\n",
        "58: potted plant\n",
        "59: bed\n",
        "60: dining table\n",
        "61: toilet\n",
        "62: tv\n",
        "63: laptop\n",
        "64: mouse\n",
        "65: remote\n",
        "66: keyboard\n",
        "67: cell phone\n",
        "68: microwave\n",
        "69: oven\n",
        "70: toaster\n",
        "71: sink\n",
        "72: refrigerator\n",
        "73: book\n",
        "74: clock\n",
        "75: vase\n",
        "76: scissors\n",
        "77: teddy bear\n",
        "78: hair drier\n",
        "79: toothbrush"
      ],
      "metadata": {
        "id": "YB54qhB0Ck_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=YOLO(\"yolov8n.pt\")\n",
        "model.train(\n",
        "    data=\"/content/dataset/coco128.yaml\",\n",
        "    epochs=3,\n",
        "    imgsz=640,\n",
        "    project=\"YOLO_Training\",\n",
        "    name=\"yolov8n_custom\""
      ],
      "metadata": {
        "id": "rIFdKrw1CmzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results=model.predict(\"/content/dataset/coco128/images/train2017/000000000078.jpg\", save=True)\n",
        "results[0].show()"
      ],
      "metadata": {
        "id": "M8opgmhvCnsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit==1.38.0 ultralytics==8.3.0 pyngrok==7.1.6 opencv-python-headless pillow pandas"
      ],
      "metadata": {
        "id": "cMzD90L8DHHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_streamlit.py\n",
        "import streamlit as st\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2, tempfile, os, glob\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "st.set_page_config(page_title=\"Object Detection (Project)\", layout=\"wide\")\n",
        "background_url = \"https://i.bb.co/FqVqvBBN/web-back.png\"\n",
        "\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "   .stApp {{\n",
        "       background: url(\"{background_url}\") no-repeat center center fixed;\n",
        "       background-size: cover;\n",
        "   }}\n",
        "   /* Sidebar styling */\n",
        "   section[data-testid=\"stSidebar\"] {{\n",
        "       background: rgba(0, 0, 0, 0.3);\n",
        "       backdrop-filter: blur(10px);\n",
        "       border-radius: 12px;\n",
        "       padding: 10px;\n",
        "   }}\n",
        "   /* File uploader styling */\n",
        "   div[data-testid=\"stFileUploader\"] {{\n",
        "       background: rgba(0, 0, 0, 0.3);\n",
        "       backdrop-filter: blur(10px);\n",
        "       border-radius: 12px;\n",
        "       padding: 15px;\n",
        "   }}\n",
        "   /* DataFrame styling */\n",
        "   .stDataFrame {{\n",
        "       background: rgba(255, 255, 255, 0.85);\n",
        "       border-radius: 12px;\n",
        "       padding: 10px;\n",
        "       box-shadow: 0 4px 10px rgba(0,0,0,0.3);\n",
        "   }}\n",
        "   /* Dark text */\n",
        "   h1, h2, h3, h4, h5, h6, p, label, span, div {{\n",
        "       color: #1a1a1a !important;\n",
        "       font-weight: 500;\n",
        "   }}\n",
        "   </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.title(\"Object Detection (Project)\")\n",
        "\n",
        "uploaded_weights = st.sidebar.file_uploader(\"Upload custom .pt weights (optional)\", type=[\"pt\"])\n",
        "conf = st.sidebar.slider(\"Confidence threshold\", 0.0,1.0, 0.25,0.01)\n",
        "img_size = st.sidebar.selectbox(\"Inference image size (px)\", [320,416,640,1280], index=2)\n",
        "\n",
        "@st.cache_resourse\n",
        "def load_model (weights_path=\"yolov8n.pt\"):\n",
        "  return YOLO(weights_path)\n",
        "\n",
        "def save_uploaded_file(uploaded_file, suffix=\"\"):\n",
        "  suffix= suffix if suffix else Path(uploaded_file.name).suffix\n",
        "  tf = tempfile.NameTemporaryFile(delete=False, suffix=suffix)\n",
        "  tf.write(uploaded_file.getbuffer())\n",
        "  tf.flush()\n",
        "  return tf.name\n",
        "\n",
        "def annotate_and_table(results, model):\n",
        "  res=results[0]\n",
        "  try:\n",
        "    plotted = res.plot()\n",
        "    annotated = cv2.cvtColor(plotted, cv2.COLOR_BGR2RGB)\n",
        "  except Exception:\n",
        "    annotated = res.orig_img if hasattr(res, \"orig_img\") else None\n",
        "\n",
        "  detections = []\n",
        "  try:\n",
        "    boxes = res.boxes\n",
        "    if boxes is not None and len(boxes) > 0:\n",
        "           for c, cf, box in zip(boxes.cls.cpu().numpy(), boxes.conf.cpu().numpy(), boxes.xyxy.cpu().numpy()):\n",
        "               name = model.names[int(c)]\n",
        "               detections.append({\"class\": name, \"conf\": float(cf), \"bbox\": [float(x) for x in box]})\n",
        "  except:\n",
        "       detections = []\n",
        "\n",
        "  return annotated, pd.DataFrame(detections)\n",
        "\n",
        "weights_to_load = \"yolov8n.pt\"\n",
        "if uploaded_weights:\n",
        "   weights_to_load = save_uploaded_file(uploaded_weights, suffix=\".pt\")\n",
        "   st.sidebar.success(\"Using uploaded weights\")\n",
        "\n",
        "model = load_model(weights_to_load)\n",
        "\n",
        "mode = st.radio(\"Select input\", [\"Image upload\", \"Video upload\"])\n",
        "\n",
        "if mode == \"Image upload\":\n",
        "   uploaded = st.file_uploader(\"Upload image\", type=[\"jpg\",\"jpeg\",\"png\"])\n",
        "   if uploaded:\n",
        "       img = Image.open(uploaded).convert(\"RGB\")\n",
        "       st.image(img, caption=\"Input image\")\n",
        "       results = model.predict(np.array(img), conf=conf, imgsz=img_size)\n",
        "       annotated, df = annotate_and_table(results, model)\n",
        "       if annotated is not None:\n",
        "           st.image(annotated, caption=\"Annotated\")\n",
        "       if not df.empty:\n",
        "           st.dataframe(df)\n",
        "\n",
        "elif mode == \"Video upload\":\n",
        "   uploaded_vid = st.file_uploader(\"Upload video\", type=[\"mp4\",\"mov\",\"avi\",\"mkv\"])\n",
        "   if uploaded_vid:\n",
        "       tmp = save_uploaded_file(uploaded_vid)\n",
        "       st.video(tmp)\n",
        "       project_dir = tempfile.mkdtemp()\n",
        "       results = model.predict(source=tmp, conf=conf, imgsz=img_size, project=project_dir, name=\"run\", save=True)\n",
        "       try:\n",
        "           out_dir = str(results[0].save_dir)\n",
        "           vids = glob.glob(os.path.join(out_dir, \"*\"))\n",
        "           vids = [v for v in vids if Path(v).suffix.lower() in [\".mp4\",\".avi\",\".mov\",\".mkv\"]]\n",
        "           if vids:\n",
        "               st.success(\"Annotated video\")\n",
        "               st.video(vids[0])\n",
        "       except:\n",
        "           st.warning(\"Could not display annotated video\")"
      ],
      "metadata": {
        "id": "VcSDDrA6DHSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "3WoLi0btDHcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"32jGxH70eocxfCx43QxP6xInVoV_2cgt7tYcgWmT9AXjbVzAc\" #Use your own authentication token.\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "!streamlit run app_streamlit.py --server.port 8501 &\n",
        "\n",
        "import time\n",
        "while True:\n",
        "  time.sleep(60)"
      ],
      "metadata": {
        "id": "1u8bS7zVDHk8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}